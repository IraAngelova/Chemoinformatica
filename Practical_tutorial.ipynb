{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical_tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCXy-s21UF_E"
      },
      "source": [
        "# **ООП**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev8KkCWfVLNB"
      },
      "source": [
        "Курс по ооп на ютуб с написанием класса и использованием его."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6jKFSa8UKJ3"
      },
      "source": [
        "class Employee:\n",
        "\n",
        "    def __init__(self, first, last, pay):\n",
        "        self.first = first\n",
        "        self.last = last\n",
        "        self.email = first + '.' + last + '@email.com'\n",
        "        self.pay = pay\n",
        "\n",
        "    def fullname(self):\n",
        "        return '{} {}'.format(self.first, self.last)\n",
        "\n",
        "emp_1 = Employee('Corey', 'Schafer', 50000)\n",
        "emp_2 = Employee('Test', 'Employee', 60000)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne3gMOwoUahu",
        "outputId": "d054bbfc-77fe-4f85-893b-ee168a264bce"
      },
      "source": [
        "class Employee:\n",
        "\n",
        "    num_of_emps = 0\n",
        "    raise_amt = 1.04\n",
        "\n",
        "    def __init__(self, first, last, pay):\n",
        "        self.first = first\n",
        "        self.last = last\n",
        "        self.email = first + '.' + last + '@email.com'\n",
        "        self.pay = pay\n",
        "\n",
        "        Employee.num_of_emps += 1\n",
        "\n",
        "    def fullname(self):\n",
        "        return '{} {}'.format(self.first, self.last)\n",
        "\n",
        "    def apply_raise(self):\n",
        "        self.pay = int(self.pay * self.raise_amt)\n",
        "\n",
        "    @classmethod\n",
        "    def set_raise_amt(cls, amount):\n",
        "        cls.raise_amt = amount\n",
        "\n",
        "    @classmethod\n",
        "    def from_string(cls, emp_str):\n",
        "        first, last, pay = emp_str.split('-')\n",
        "        return cls(first, last, pay)\n",
        "\n",
        "    @staticmethod\n",
        "    def is_workday(day):\n",
        "        if day.weekday() == 5 or day.weekday() == 6:\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "\n",
        "emp_1 = Employee('Corey', 'Schafer', 50000)\n",
        "emp_2 = Employee('Test', 'Employee', 60000)\n",
        "\n",
        "Employee.set_raise_amt(1.05)\n",
        "\n",
        "print(Employee.raise_amt)\n",
        "print(emp_1.raise_amt)\n",
        "print(emp_2.raise_amt)\n",
        "\n",
        "emp_str_1 = 'John-Doe-70000'\n",
        "emp_str_2 = 'Steve-Smith-30000'\n",
        "emp_str_3 = 'Jane-Doe-90000'\n",
        "\n",
        "first, last, pay = emp_str_1.split('-')\n",
        "\n",
        "#new_emp_1 = Employee(first, last, pay)\n",
        "new_emp_1 = Employee.from_string(emp_str_1)\n",
        "\n",
        "print(new_emp_1.email)\n",
        "print(new_emp_1.pay)\n",
        "\n",
        "import datetime\n",
        "my_date = datetime.date(2016, 7, 11)\n",
        "\n",
        "print(Employee.is_workday(my_date))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.05\n",
            "1.05\n",
            "1.05\n",
            "John.Doe@email.com\n",
            "70000\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaXXpbVNUmpB",
        "outputId": "a2c48c51-9169-40ce-9e20-1b2b7e02af16"
      },
      "source": [
        "class Employee:\n",
        "\n",
        "    raise_amt = 1.04\n",
        "\n",
        "    def __init__(self, first, last, pay):\n",
        "        self.first = first\n",
        "        self.last = last\n",
        "        self.email = first + '.' + last + '@email.com'\n",
        "        self.pay = pay\n",
        "\n",
        "    def fullname(self):\n",
        "        return '{} {}'.format(self.first, self.last)\n",
        "\n",
        "    def apply_raise(self):\n",
        "        self.pay = int(self.pay * self.raise_amt)\n",
        "\n",
        "\n",
        "class Developer(Employee):\n",
        "    raise_amt = 1.10\n",
        "\n",
        "    def __init__(self, first, last, pay, prog_lang):\n",
        "        super().__init__(first, last, pay)\n",
        "        self.prog_lang = prog_lang\n",
        "\n",
        "\n",
        "class Manager(Employee):\n",
        "\n",
        "    def __init__(self, first, last, pay, employees=None):\n",
        "        super().__init__(first, last, pay)\n",
        "        if employees is None:\n",
        "            self.employees = []\n",
        "        else:\n",
        "            self.employees = employees\n",
        "\n",
        "    def add_emp(self, emp):\n",
        "        if emp not in self.employees:\n",
        "            self.employees.append(emp)\n",
        "\n",
        "    def remove_emp(self, emp):\n",
        "        if emp in self.employees:\n",
        "            self.employees.remove(emp)\n",
        "\n",
        "    def print_emps(self):\n",
        "        for emp in self.employees:\n",
        "            print('-->', emp.fullname())\n",
        "\n",
        "\n",
        "dev_1 = Developer('Corey', 'Schafer', 50000, 'Python')\n",
        "dev_2 = Developer('Test', 'Employee', 60000, 'Java')\n",
        "\n",
        "mgr_1 = Manager('Sue', 'Smith', 90000, [dev_1])\n",
        "\n",
        "print(mgr_1.email)\n",
        "\n",
        "mgr_1.add_emp(dev_2)\n",
        "mgr_1.remove_emp(dev_2)\n",
        "\n",
        "mgr_1.print_emps()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sue.Smith@email.com\n",
            "--> Corey Schafer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9deYLCiUKRZ",
        "outputId": "d64274e7-1d42-46ec-8ed3-c3d924eb357e"
      },
      "source": [
        "class Employee:\n",
        "\n",
        "    raise_amt = 1.04\n",
        "\n",
        "    def __init__(self, first, last, pay):\n",
        "        self.first = first\n",
        "        self.last = last\n",
        "        self.email = first + '.' + last + '@email.com'\n",
        "        self.pay = pay\n",
        "\n",
        "    def fullname(self):\n",
        "        return '{} {}'.format(self.first, self.last)\n",
        "\n",
        "    def apply_raise(self):\n",
        "        self.pay = int(self.pay * self.raise_amt)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"Employee('{}', '{}', {})\".format(self.first, self.last, self.pay)\n",
        "\n",
        "    def __str__(self):\n",
        "        return '{} - {}'.format(self.fullname(), self.email)\n",
        "\n",
        "    def __add__(self, other):\n",
        "        return self.pay + other.pay\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fullname())\n",
        "\n",
        "\n",
        "emp_1 = Employee('Corey', 'Schafer', 50000)\n",
        "emp_2 = Employee('Test', 'Employee', 60000)\n",
        "\n",
        "# print(emp_1 + emp_2)\n",
        "\n",
        "print(len(emp_1))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHXbXzjpU7Wd",
        "outputId": "851b4030-ab61-4f23-8f5b-d2c7251d8306"
      },
      "source": [
        "class Employee:\n",
        "\n",
        "    def __init__(self, first, last):\n",
        "        self.first = first\n",
        "        self.last = last\n",
        "\n",
        "    @property\n",
        "    def email(self):\n",
        "        return '{}.{}@email.com'.format(self.first, self.last)\n",
        "\n",
        "    @property\n",
        "    def fullname(self):\n",
        "        return '{} {}'.format(self.first, self.last)\n",
        "    \n",
        "    @fullname.setter\n",
        "    def fullname(self, name):\n",
        "        first, last = name.split(' ')\n",
        "        self.first = first\n",
        "        self.last = last\n",
        "    \n",
        "    @fullname.deleter\n",
        "    def fullname(self):\n",
        "        print('Delete Name!')\n",
        "        self.first = None\n",
        "        self.last = None\n",
        "\n",
        "\n",
        "emp_1 = Employee('John', 'Smith')\n",
        "emp_1.fullname = \"Corey Schafer\"\n",
        "\n",
        "print(emp_1.first)\n",
        "print(emp_1.email)\n",
        "print(emp_1.fullname)\n",
        "\n",
        "del emp_1.fullname"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corey\n",
            "Corey.Schafer@email.com\n",
            "Corey Schafer\n",
            "Delete Name!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "socSJe925zFv"
      },
      "source": [
        "#  Working With Datasets\n",
        "\n",
        "Data is central to machine learning.  This tutorial introduces the `Dataset` class that DeepChem uses to store and manage data.  It provides simple but powerful tools for efficiently working with large amounts of data.  It also is designed to easily interact with other popular Python frameworks such as NumPy, Pandas, TensorFlow, and PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMWAv-Z46nCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fcd8f90-32b2-4398-ef93-a8ee37a62af0"
      },
      "source": [
        "!pip install --pre deepchem"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepchem\n",
            "  Downloading deepchem-2.6.0.dev20211026183818-py3-none-any.whl (610 kB)\n",
            "\u001b[K     |████████████████████████████████| 610 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Installing collected packages: deepchem\n",
            "Successfully installed deepchem-2.6.0.dev20211026183818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le_JAwjb8wP2",
        "outputId": "6faf3a68-19f1-42a8-b54c-0ffee14b4359"
      },
      "source": [
        "pip install rdkit-pypi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2021.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.4 MB 36.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi) (1.19.5)\n",
            "Installing collected packages: rdkit-pypi\n",
            "Successfully installed rdkit-pypi-2021.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk47QTZ95zF-"
      },
      "source": [
        "We can now import the `deepchem` package to play with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "PDiY03h35zF_",
        "outputId": "9b2f77af-5ce8-479d-a8c9-995e58d46c1f"
      },
      "source": [
        "import deepchem as dc\n",
        "dc.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0.dev'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0u7qIZd5zGG"
      },
      "source": [
        "# Anatomy of a Dataset\n",
        "\n",
        "The Delaney dataset of molecular solubilities: https://github.com/deepchem/deepchem/blob/master/datasets/delaney-processed.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saTaOpXY5zGI"
      },
      "source": [
        "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')\n",
        "train_dataset, valid_dataset, test_dataset = datasets"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F922OPtL5zGM"
      },
      "source": [
        "We now have three Dataset objects: the training, validation, and test sets.  What information does each of them contain?  We can start to get an idea by printing out the string representation of one of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCsxJ_JkbJDW",
        "outputId": "0ed1b246-5695-49d9-ef66-bd469a88dde4"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DiskDataset X.shape: (902,), y.shape: (902, 1), w.shape: (902, 1), ids: ['CC(C)=CCCC(C)=CC(=O)' 'CCCC=C' 'CCCCCCCCCCCCCC' ...\n",
              " 'Nc2cccc3nc1ccccc1cc23 ' 'C1CCCCCC1' 'OC1CCCCCC1'], task_names: ['measured log solubility in mols per litre']>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEDcUsz35zGO",
        "outputId": "640e691d-8ec6-4fe8-efa7-c7f30e8c1ada"
      },
      "source": [
        "print(test_dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<DiskDataset X.shape: (113,), y.shape: (113, 1), w.shape: (113, 1), ids: ['c1cc2ccc3cccc4ccc(c1)c2c34' 'Cc1cc(=O)[nH]c(=S)[nH]1'\n",
            " 'Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 ' ...\n",
            " 'c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43' 'Cc1occc1C(=O)Nc2ccccc2'\n",
            " 'OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)C(O)C3O '], task_names: ['measured log solubility in mols per litre']>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8UCFrrN5zGf"
      },
      "source": [
        "There's a lot of information there, so let's start at the beginning.  It begins with the label \"DiskDataset\".  Dataset is an abstract class.  It has a few subclasses that correspond to different ways of storing data.\n",
        "\n",
        "- `DiskDataset` is a dataset that has been saved to disk.  The data is stored in a way that can be efficiently accessed, even if the total amount of data is far larger than your computer's memory.\n",
        "- `NumpyDataset` is an in-memory dataset that holds all the data in NumPy arrays.  It is a useful tool when manipulating small to medium sized datasets that can fit entirely in memory.\n",
        "- `ImageDataset` is a more specialized class that stores some or all of the data in image files on disk.  It is useful when working with models that have images as their inputs or outputs.\n",
        "\n",
        "Now let's consider the contents of the Dataset.  Every Dataset stores a list of *samples*.  Very roughly speaking, a sample is a single data point.  In this case, each sample is a molecule.  In other datasets a sample might correspond to an experimental assay, a cell line, an image, or many other things.  For every sample the dataset stores the following information.\n",
        "\n",
        "- The *features*, referred to as `X`.  This is the input that should be fed into a model to represent the sample.\n",
        "- The *labels*, referred to as `y`.  This is the desired output from the model.  During training, it tries to make the model's output for each sample as close as possible to `y`.\n",
        "- The *weights*, referred to as `w`.  This can be used to indicate that some data values are more important than others.  In later tutorials we will see examples of how this is useful.\n",
        "- An *ID*, which is a unique identifier for the sample.  This can be anything as long as it is unique.  Sometimes it is just an integer index, but in this dataset the ID is a SMILES string describing the molecule.\n",
        "\n",
        "Notice that `X`, `y`, and `w` all have 113 as the size of their first dimension.  That means this dataset contains 113 samples.\n",
        "\n",
        "The final piece of information listed in the output is `task_names`.  Some datasets contain multiple pieces of information for each sample.  For example, if a sample represents a molecule, the dataset might record the results of several different experiments on that molecule.  This dataset has only a single task: \"measured log solubility in mols per litre\".  Also notice that `y` and `w` each have shape (113, 1).  The second dimension of these arrays usually matches the number of tasks.\n",
        "\n",
        "# Accessing Data from a Dataset\n",
        "\n",
        "There are many ways to access the data contained in a dataset.  The simplest is just to directly access the `X`, `y`, `w`, and `ids` properties.  Each of these returns the corresponding information as a NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5K3rdGV5zGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f5c11e-0622-492f-82e2-751b6ecb77d9"
      },
      "source": [
        "test_dataset.ids"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['c1cc2ccc3cccc4ccc(c1)c2c34', 'Cc1cc(=O)[nH]c(=S)[nH]1',\n",
              "       'Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 ',\n",
              "       'c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45', 'C1=Cc2cccc3cccc1c23',\n",
              "       'CC1CO1', 'CCN2c1ccccc1N(C)C(=S)c3cccnc23 ',\n",
              "       'CC12CCC3C(CCc4cc(O)ccc34)C2CCC1=O',\n",
              "       'Cn2cc(c1ccccc1)c(=O)c(c2)c3cccc(c3)C(F)(F)F',\n",
              "       'ClC(Cl)(Cl)C(NC=O)N1C=CN(C=C1)C(NC=O)C(Cl)(Cl)Cl ',\n",
              "       'COc2c1occc1cc3ccc(=O)oc23 ',\n",
              "       'CN2C(=C(O)c1ccccc1S2(=O)=O)C(=O)Nc3ccccn3 ',\n",
              "       'Cc3cc2nc1c(=O)[nH]c(=O)nc1n(CC(O)C(O)C(O)CO)c2cc3C',\n",
              "       'c1ccc(cc1)c2ccc(cc2)c3ccccc3',\n",
              "       'CC34CC(=O)C1C(CCC2=CC(=O)CCC12C)C3CCC4(=O) ',\n",
              "       'c1ccc2c(c1)sc3ccccc23',\n",
              "       'CC23Cc1cnoc1C=C2CCC4C3CCC5(C)C4CCC5(O)C#C',\n",
              "       'OC(C(=O)c1ccccc1)c2ccccc2', 'OCC2OC(Oc1ccccc1CO)C(O)C(O)C2O',\n",
              "       'CC3C2CCC1(C)C=CC(=O)C(=C1C2OC3=O)C', 'O=Cc2ccc1OCOc1c2 ',\n",
              "       'CC1CCCCC1NC(=O)Nc2ccccc2',\n",
              "       'CC(=O)N(S(=O)c1ccc(N)cc1)c2onc(C)c2C ',\n",
              "       'C1N(C(=O)NCC(C)C)C(=O)NC1', 'CNC(=O)Oc1ccccc1C2OCCO2',\n",
              "       'CC1=C(CCCO1)C(=O)Nc2ccccc2 ', 'Cn2c(=O)on(c1ccc(Cl)c(Cl)c1)c2=O',\n",
              "       'C1Cc2cccc3cccc1c23', 'c1ccc2cc3c4cccc5cccc(c3cc2c1)c45',\n",
              "       'Nc1cc(nc(N)n1=O)N2CCCCC2 ',\n",
              "       'O=c2c(C3CCCc4ccccc43)c(O)c1ccccc1o2 ',\n",
              "       'CC(C)C(Nc1ccc(cc1Cl)C(F)(F)F)C(=O)OC(C#N)c2cccc(Oc3ccccc3)c2',\n",
              "       'Cc1c(F)c(F)c(COC(=O)C2C(C=C(Cl)C(F)(F)F)C2(C)C)c(F)c1F',\n",
              "       'c2ccc1[nH]nnc1c2', 'c2ccc1ocnc1c2', 'CCOC(=O)c1cncn1C(C)c2ccccc2',\n",
              "       'CCN2c1ccccc1N(C)C(=O)c3ccccc23 ',\n",
              "       'OCC(O)COC(=O)c1ccccc1Nc2ccnc3cc(Cl)ccc23',\n",
              "       'OCC1OC(OC2C(O)C(O)C(O)OC2CO)C(O)C(O)C1O',\n",
              "       'CC34CCc1c(ccc2cc(O)ccc12)C3CCC4=O',\n",
              "       'ClC1=C(Cl)C(Cl)(C(=C1Cl)Cl)C2(Cl)C(=C(Cl)C(=C2Cl)Cl)Cl',\n",
              "       'ClC1(C(=O)C2(Cl)C3(Cl)C14Cl)C5(Cl)C2(Cl)C3(Cl)C(Cl)(Cl)C45Cl',\n",
              "       'Oc1ccc(c(O)c1)c3oc2cc(O)cc(O)c2c(=O)c3O ', 'C1SC(=S)NC1(=O)',\n",
              "       'ClC(Cl)C(Cl)(Cl)SN2C(=O)C1CC=CCC1C2=O ',\n",
              "       'ClC1=C(Cl)C2(Cl)C3C4CC(C=C4)C3C1(Cl)C2(Cl)Cl',\n",
              "       'CC(=O)Nc1nnc(s1)S(N)(=O)=O ', 'CC1=C(SCCO1)C(=O)Nc2ccccc2',\n",
              "       'CN(C(=O)COc1nc2ccccc2s1)c3ccccc3',\n",
              "       'CN(C(=O)NC(C)(C)c1ccccc1)c2ccccc2', 'Nc1nccs1 ',\n",
              "       'CN(C=Nc1ccc(C)cc1C)C=Nc2ccc(C)cc2C',\n",
              "       'OCC(O)C2OC1OC(OC1C2O)C(Cl)(Cl)Cl ',\n",
              "       'Nc3nc(N)c2nc(c1ccccc1)c(N)nc2n3',\n",
              "       'CC2Nc1cc(Cl)c(cc1C(=O)N2c3ccccc3C)S(N)(=O)=O ',\n",
              "       'CN1CC(O)N(C1=O)c2nnc(s2)C(C)(C)C',\n",
              "       'CCC1(C(=O)NC(=O)NC1=O)C2=CCC3CCC2C3',\n",
              "       'CCC(C)C(=O)OC2CC(C)C=C3C=CC(C)C(CCC1CC(O)CC(=O)O1)C23 ',\n",
              "       'CC2Cc1ccccc1N2NC(=O)c3ccc(Cl)c(c3)S(N)(=O)=O ',\n",
              "       'o1c2ccccc2c3ccccc13', 'O=C(Nc1ccccc1)Nc2ccccc2',\n",
              "       'c1ccc2c(c1)c3cccc4c3c2cc5ccccc54',\n",
              "       'COc1ccc(cc1)C(O)(C2CC2)c3cncnc3 ', 'c1cnc2c(c1)ccc3ncccc23',\n",
              "       'OCC1OC(CO)(OC2OC(COC3OC(CO)C(O)C(O)C3O)C(O)C(O)C2O)C(O)C1O',\n",
              "       'CCOC(=O)c1ccccc1S(=O)(=O)NN(C=O)c2nc(Cl)cc(OC)n2',\n",
              "       'CC34CCC1C(=CCc2cc(O)ccc12)C3CCC4=O',\n",
              "       'CN(C)C(=O)Oc1cc(C)nn1c2ccccc2',\n",
              "       'OC(Cn1cncn1)(c2ccc(F)cc2)c3ccccc3F',\n",
              "       'Cc1c2ccccc2c(C)c3ccc4ccccc4c13',\n",
              "       'Cc3nnc4CN=C(c1ccccc1Cl)c2cc(Cl)ccc2n34',\n",
              "       'Cc3ccnc4N(C1CC1)c2ncccc2C(=O)Nc34 ',\n",
              "       'c1cc2cccc3c4cccc5cccc(c(c1)c23)c54',\n",
              "       'COc1cc(cc(OC)c1O)C6C2C(COC2=O)C(OC4OC3COC(C)OC3C(O)C4O)c7cc5OCOc5cc67',\n",
              "       'O=c1[nH]cnc2nc[nH]c12 ',\n",
              "       'C1C(O)CCC2(C)CC3CCC4(C)C5(C)CC6OCC(C)CC6OC5CC4C3C=C21',\n",
              "       'Cc1ccccc1n3c(C)nc2ccccc2c3=O',\n",
              "       'CCOc1ccc(cc1)C(C)(C)COCc3cccc(Oc2ccccc2)c3',\n",
              "       'CCC1(CCC(=O)NC1=O)c2ccccc2 ',\n",
              "       'CC1CC(C)C(=O)C(C1)C(O)CC2CC(=O)NC(=O)C2 ',\n",
              "       'CC(=O)C3CCC4C2CC=C1CC(O)CCC1(C)C2CCC34C ',\n",
              "       'Cc1ccc(OP(=O)(Oc2cccc(C)c2)Oc3ccccc3C)cc1',\n",
              "       'CSc1nnc(c(=O)n1N)C(C)(C)C', 'Nc1ncnc2n(ccc12)C3OC(CO)C(O)C3O ',\n",
              "       'O=C2NC(=O)C1(CC1)C(=O)N2 ', 'C1Cc2ccccc2C1', 'c1ccc2cnccc2c1',\n",
              "       'OCC1OC(C(O)C1O)n2cnc3c(O)ncnc23',\n",
              "       'c2(Cl)c(Cl)c(Cl)c1nccnc1c2(Cl) ', 'C1OC1c2ccccc2 ',\n",
              "       'CCC(=C(CC)c1ccc(O)cc1)c2ccc(O)cc2 ', 'c1ccc2c(c1)c3cccc4cccc2c34',\n",
              "       'CC(C)C(C(=O)OC(C#N)c1cccc(Oc2ccccc2)c1)c3ccc(OC(F)F)cc3',\n",
              "       'CCCC1COC(Cn2cncn2)(O1)c3ccc(Cl)cc3Cl',\n",
              "       'O=C2CN(N=Cc1ccc(o1)N(=O)=O)C(=O)N2 ', 'NC(=O)c1cnccn1',\n",
              "       'OC4=C(C1CCC(CC1)c2ccc(Cl)cc2)C(=O)c3ccccc3C4=O',\n",
              "       'O=C(Cn1ccnc1N(=O)=O)NCc2ccccc2',\n",
              "       'CCC1(C(=O)NC(=O)NC1=O)C2=CCCCC2 ',\n",
              "       'COC(=O)C1=C(C)NC(=C(C1c2ccccc2N(=O)=O)C(=O)OC)C ',\n",
              "       'O=C2NC(=O)C1(CCC1)C(=O)N2', 'CCCOP(=S)(OCCC)SCC(=O)N1CCCCC1C',\n",
              "       'N(c1ccccc1)c2ccccc2', 'ClC(Cl)=C(c1ccc(Cl)cc1)c2ccc(Cl)cc2',\n",
              "       'O=c2[nH]c1CCCc1c(=O)n2C3CCCCC3', 'CCC1(C(=O)NCNC1=O)c2ccccc2',\n",
              "       'O=C1CCCN1', 'COc5cc4OCC3Oc2c1CC(Oc1ccc2C(=O)C3c4cc5OC)C(C)=C ',\n",
              "       'ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl', 'c1ccsc1',\n",
              "       'c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43', 'Cc1occc1C(=O)Nc2ccccc2',\n",
              "       'OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)C(O)C3O '],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zcd7jTd5zGr"
      },
      "source": [
        "This is a very easy way to access data, but you should be very careful about using it.  This requires the data for all samples to be loaded into memory at once.  That's fine for small datasets like this one, but for large datasets it could easily take more memory than you have.\n",
        "\n",
        "A better approach is to iterate over the dataset.  That lets it load just a little data at a time, process it, then free the memory before loading the next bit.  You can use the `itersamples()` method to iterate over samples one at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJc90fs_5zGs",
        "outputId": "0b92740a-41cc-4214-b3af-950cae0e3921"
      },
      "source": [
        "for X, y, w, id in test_dataset.itersamples():\n",
        "    print(y, id)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.60114461] c1cc2ccc3cccc4ccc(c1)c2c34\n",
            "[0.20848251] Cc1cc(=O)[nH]c(=S)[nH]1\n",
            "[-0.01602738] Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 \n",
            "[-2.82191713] c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45\n",
            "[-0.52891635] C1=Cc2cccc3cccc1c23\n",
            "[1.10168349] CC1CO1\n",
            "[-0.88987406] CCN2c1ccccc1N(C)C(=S)c3cccnc23 \n",
            "[-0.52649706] CC12CCC3C(CCc4cc(O)ccc34)C2CCC1=O\n",
            "[-0.76358725] Cn2cc(c1ccccc1)c(=O)c(c2)c3cccc(c3)C(F)(F)F\n",
            "[-0.64020358] ClC(Cl)(Cl)C(NC=O)N1C=CN(C=C1)C(NC=O)C(Cl)(Cl)Cl \n",
            "[-0.38569452] COc2c1occc1cc3ccc(=O)oc23 \n",
            "[-0.62568785] CN2C(=C(O)c1ccccc1S2(=O)=O)C(=O)Nc3ccccn3 \n",
            "[-0.39585553] Cc3cc2nc1c(=O)[nH]c(=O)nc1n(CC(O)C(O)C(O)CO)c2cc3C\n",
            "[-2.05306753] c1ccc(cc1)c2ccc(cc2)c3ccccc3\n",
            "[-0.29666474] CC34CC(=O)C1C(CCC2=CC(=O)CCC12C)C3CCC4(=O) \n",
            "[-0.73213651] c1ccc2c(c1)sc3ccccc23\n",
            "[-1.27744393] CC23Cc1cnoc1C=C2CCC4C3CCC5(C)C4CCC5(O)C#C\n",
            "[0.0081655] OC(C(=O)c1ccccc1)c2ccccc2\n",
            "[0.97588054] OCC2OC(Oc1ccccc1CO)C(O)C(O)C2O\n",
            "[-0.10796031] CC3C2CCC1(C)C=CC(=O)C(=C1C2OC3=O)C\n",
            "[0.59847167] O=Cc2ccc1OCOc1c2 \n",
            "[-0.60149498] CC1CCCCC1NC(=O)Nc2ccccc2\n",
            "[-0.34988907] CC(=O)N(S(=O)c1ccc(N)cc1)c2onc(C)c2C \n",
            "[0.34686576] C1N(C(=O)NCC(C)C)C(=O)NC1\n",
            "[0.62750312] CNC(=O)Oc1ccccc1C2OCCO2\n",
            "[0.14848418] CC1=C(CCCO1)C(=O)Nc2ccccc2 \n",
            "[0.02268122] Cn2c(=O)on(c1ccc(Cl)c(Cl)c1)c2=O\n",
            "[-0.85310089] C1Cc2cccc3cccc1c23\n",
            "[-2.72079091] c1ccc2cc3c4cccc5cccc(c3cc2c1)c45\n",
            "[0.42476682] Nc1cc(nc(N)n1=O)N2CCCCC2 \n",
            "[0.01300407] O=c2c(C3CCCc4ccccc43)c(O)c1ccccc1o2 \n",
            "[-2.4851523] CC(C)C(Nc1ccc(cc1Cl)C(F)(F)F)C(=O)OC(C#N)c2cccc(Oc3ccccc3)c2\n",
            "[-2.15516147] Cc1c(F)c(F)c(COC(=O)C2C(C=C(Cl)C(F)(F)F)C2(C)C)c(F)c1F\n",
            "[1.00975056] c2ccc1[nH]nnc1c2\n",
            "[0.82588471] c2ccc1ocnc1c2\n",
            "[-0.90390593] CCOC(=O)c1cncn1C(C)c2ccccc2\n",
            "[-0.91067993] CCN2c1ccccc1N(C)C(=O)c3ccccc23 \n",
            "[-0.82455329] OCC(O)COC(=O)c1ccccc1Nc2ccnc3cc(Cl)ccc23\n",
            "[1.26909819] OCC1OC(OC2C(O)C(O)C(O)OC2CO)C(O)C(O)C1O\n",
            "[-1.14825397] CC34CCc1c(ccc2cc(O)ccc12)C3CCC4=O\n",
            "[-2.1343556] ClC1=C(Cl)C(Cl)(C(=C1Cl)Cl)C2(Cl)C(=C(Cl)C(=C2Cl)Cl)Cl\n",
            "[-1.15744727] ClC1(C(=O)C2(Cl)C3(Cl)C14Cl)C5(Cl)C2(Cl)C3(Cl)C(Cl)(Cl)C45Cl\n",
            "[-0.1045733] Oc1ccc(c(O)c1)c3oc2cc(O)cc(O)c2c(=O)c3O \n",
            "[0.53073162] C1SC(=S)NC1(=O)\n",
            "[-1.22567118] ClC(Cl)C(Cl)(Cl)SN2C(=O)C1CC=CCC1C2=O \n",
            "[-1.66452995] ClC1=C(Cl)C2(Cl)C3C4CC(C=C4)C3C1(Cl)C2(Cl)Cl\n",
            "[0.24525568] CC(=O)Nc1nnc(s1)S(N)(=O)=O \n",
            "[-0.13215318] CC1=C(SCCO1)C(=O)Nc2ccccc2\n",
            "[-0.97067826] CN(C(=O)COc1nc2ccccc2s1)c3ccccc3\n",
            "[-0.23376326] CN(C(=O)NC(C)(C)c1ccccc1)c2ccccc2\n",
            "[1.21297072] Nc1nccs1 \n",
            "[-1.2595412] CN(C=Nc1ccc(C)cc1C)C=Nc2ccc(C)cc2C\n",
            "[0.49686159] OCC(O)C2OC1OC(OC1C2O)C(Cl)(Cl)Cl \n",
            "[0.22396595] Nc3nc(N)c2nc(c1ccccc1)c(N)nc2n3\n",
            "[-0.44182199] CC2Nc1cc(Cl)c(cc1C(=O)N2c3ccccc3C)S(N)(=O)=O \n",
            "[0.47895886] CN1CC(O)N(C1=O)c2nnc(s2)C(C)(C)C\n",
            "[0.08267956] CCC1(C(=O)NC(=O)NC1=O)C2=CCC3CCC2C3\n",
            "[-1.51840498] CCC(C)C(=O)OC2CC(C)C=C3C=CC(C)C(CCC1CC(O)CC(=O)O1)C23 \n",
            "[-0.34795364] CC2Cc1ccccc1N2NC(=O)c3ccc(Cl)c(c3)S(N)(=O)=O \n",
            "[-0.83858516] o1c2ccccc2c3ccccc13\n",
            "[-0.13699176] O=C(Nc1ccccc1)Nc2ccccc2\n",
            "[-2.59498796] c1ccc2c(c1)c3cccc4c3c2cc5ccccc54\n",
            "[0.13106531] COc1ccc(cc1)C(O)(C2CC2)c3cncnc3 \n",
            "[0.09042128] c1cnc2c(c1)ccc3ncccc23\n",
            "[1.18877785] OCC1OC(CO)(OC2OC(COC3OC(CO)C(O)C(O)C3O)C(O)C(O)C2O)C(O)C1O\n",
            "[-0.82697258] CCOC(=O)c1ccccc1S(=O)(=O)NN(C=O)c2nc(Cl)cc(OC)n2\n",
            "[-1.16857599] CC34CCC1C(=CCc2cc(O)ccc12)C3CCC4=O\n",
            "[0.37589721] CN(C)C(=O)Oc1cc(C)nn1c2ccccc2\n",
            "[-0.24344041] OC(Cn1cncn1)(c2ccc(F)cc2)c3ccccc3F\n",
            "[-2.00952036] Cc1c2ccccc2c(C)c3ccc4ccccc4c13\n",
            "[-0.59181783] Cc3nnc4CN=C(c1ccccc1Cl)c2cc(Cl)ccc2n34\n",
            "[-0.15634606] Cc3ccnc4N(C1CC1)c2ncccc2C(=O)Nc34 \n",
            "[-2.87272217] c1cc2cccc3c4cccc5cccc(c(c1)c23)c54\n",
            "[-0.34069577] COc1cc(cc(OC)c1O)C6C2C(COC2=O)C(OC4OC3COC(C)OC3C(O)C4O)c7cc5OCOc5cc67\n",
            "[0.27622256] O=c1[nH]cnc2nc[nH]c12 \n",
            "[-2.15467761] C1C(O)CCC2(C)CC3CCC4(C)C5(C)CC6OCC(C)CC6OC5CC4C3C=C21\n",
            "[-0.02812382] Cc1ccccc1n3c(C)nc2ccccc2c3=O\n",
            "[-2.77401524] CCOc1ccc(cc1)C(C)(C)COCc3cccc(Oc2ccccc2)c3\n",
            "[0.25638441] CCC1(CCC(=O)NC1=O)c2ccccc2 \n",
            "[0.84040043] CC1CC(C)C(=O)C(C1)C(O)CC2CC(=O)NC(=O)C2 \n",
            "[-0.86277804] CC(=O)C3CCC4C2CC=C1CC(O)CCC1(C)C2CCC34C \n",
            "[-1.52082426] Cc1ccc(OP(=O)(Oc2cccc(C)c2)Oc3ccccc3C)cc1\n",
            "[0.29702844] CSc1nnc(c(=O)n1N)C(C)(C)C\n",
            "[0.44363727] Nc1ncnc2n(ccc12)C3OC(CO)C(O)C3O \n",
            "[0.47460415] O=C2NC(=O)C1(CC1)C(=O)N2 \n",
            "[-0.08376743] C1Cc2ccccc2C1\n",
            "[0.68556602] c1ccc2cnccc2c1\n",
            "[0.79201468] OCC1OC(C(O)C1O)n2cnc3c(O)ncnc23\n",
            "[-1.2401869] c2(Cl)c(Cl)c(Cl)c1nccnc1c2(Cl) \n",
            "[0.6129874] C1OC1c2ccccc2 \n",
            "[-0.58214068] CCC(=C(CC)c1ccc(O)cc1)c2ccc(O)cc2 \n",
            "[-1.51598569] c1ccc2c(c1)c3cccc4cccc2c34\n",
            "[-1.93984487] CC(C)C(C(=O)OC(C#N)c1cccc(Oc2ccccc2)c1)c3ccc(OC(F)F)cc3\n",
            "[-0.30295489] CCCC1COC(Cn2cncn2)(O1)c3ccc(Cl)cc3Cl\n",
            "[-0.24827899] O=C2CN(N=Cc1ccc(o1)N(=O)=O)C(=O)N2 \n",
            "[1.06442646] NC(=O)c1cnccn1\n",
            "[-1.48259952] OC4=C(C1CCC(CC1)c2ccc(Cl)cc2)C(=O)c3ccccc3C4=O\n",
            "[0.0275198] O=C(Cn1ccnc1N(=O)=O)NCc2ccccc2\n",
            "[0.33718861] CCC1(C(=O)NC(=O)NC1=O)C2=CCCCC2 \n",
            "[-0.91600236] COC(=O)C1=C(C)NC(=C(C1c2ccccc2N(=O)=O)C(=O)OC)C \n",
            "[0.58637523] O=C2NC(=O)C1(CCC1)C(=O)N2\n",
            "[-0.62084928] CCCOP(=S)(OCCC)SCC(=O)N1CCCCC1C\n",
            "[-0.30827732] N(c1ccccc1)c2ccccc2\n",
            "[-1.95145746] ClC(Cl)=C(c1ccc(Cl)cc1)c2ccc(Cl)cc2\n",
            "[-0.83568202] O=c2[nH]c1CCCc1c(=O)n2C3CCCCC3\n",
            "[0.10977558] CCC1(C(=O)NCNC1=O)c2ccccc2\n",
            "[1.90488697] O=C1CCCN1\n",
            "[-0.75149081] COc5cc4OCC3Oc2c1CC(Oc1ccc2C(=O)C3c4cc5OC)C(C)=C \n",
            "[-1.65630437] ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl\n",
            "[0.74362893] c1ccsc1\n",
            "[-2.42079925] c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43\n",
            "[-0.20957039] Cc1occc1C(=O)Nc2ccccc2\n",
            "[1.01458914] OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)C(O)C3O \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQa88cbj5zGw"
      },
      "source": [
        "Most deep learning models can process a batch of multiple samples all at once.  You can use `iterbatches()` to iterate over batches of samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSVqeYox5zGx",
        "outputId": "d27c2ee5-9f67-4bd7-e378-8b8fffef41d8"
      },
      "source": [
        "for X, y, w, ids in test_dataset.iterbatches(batch_size=50):\n",
        "    print(y.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 1)\n",
            "(50, 1)\n",
            "(13, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-o8tcL453O8"
      },
      "source": [
        "`iterbatches()` has other features that are useful when training models.  For example, `iterbatches(batch_size=100, epochs=10, deterministic=False)` will iterate over the complete dataset ten times, each time with the samples in a different random order.\n",
        "\n",
        "Datasets can also expose data using the standard interfaces for TensorFlow and PyTorch.  To get a `tensorflow.data.Dataset`, call `make_tf_dataset()`.  To get a `torch.utils.data.IterableDataset`, call `make_pytorch_dataset()`.  See the API documentation for more details.\n",
        "\n",
        "The final way of accessing data is `to_dataframe()`.  This copies the data into a Pandas `DataFrame`.  This requires storing all the data in memory at once, so you should only use it with small datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIqDiWKC53O9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "b9c973f7-3b48-4347-89a9-add856510f8b"
      },
      "source": [
        "test_dataset.to_dataframe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>y</th>\n",
              "      <th>w</th>\n",
              "      <th>ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
              "      <td>-1.601145</td>\n",
              "      <td>1.0</td>\n",
              "      <td>c1cc2ccc3cccc4ccc(c1)c2c34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
              "      <td>0.208483</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cc1cc(=O)[nH]c(=S)[nH]1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
              "      <td>-0.016027</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
              "      <td>-2.821917</td>\n",
              "      <td>1.0</td>\n",
              "      <td>c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
              "      <td>-0.528916</td>\n",
              "      <td>1.0</td>\n",
              "      <td>C1=Cc2cccc3cccc1c23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
              "      <td>-1.656304</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
              "      <td>0.743629</td>\n",
              "      <td>1.0</td>\n",
              "      <td>c1ccsc1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
              "      <td>-2.420799</td>\n",
              "      <td>1.0</td>\n",
              "      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
              "      <td>-0.209570</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
              "      <td>1.014589</td>\n",
              "      <td>1.0</td>\n",
              "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>113 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     X  ...                                                ids\n",
              "0    <deepchem.feat.mol_graphs.ConvMol object at 0x...  ...                         c1cc2ccc3cccc4ccc(c1)c2c34\n",
              "1    <deepchem.feat.mol_graphs.ConvMol object at 0x...  ...                            Cc1cc(=O)[nH]c(=S)[nH]1\n",
              "2    <deepchem.feat.mol_graphs.ConvMol object at 0x...  ...         Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 \n",
              "3    <deepchem.feat.mol_graphs.ConvMol object at 0x...  ...                   c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45\n",
              "4    <deepchem.feat.mol_graphs.ConvMol object at 0x...  ...                                C1=Cc2cccc3cccc1c23\n",
              "..                                                 ...  ...                                                ...\n",
              "108  <deepchem.feat.mol_graphs.ConvMol object at 0x...  ...     ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl\n",
              "109  <deepchem.feat.mol_graphs.ConvMol object at 0x...  ...                                            c1ccsc1\n",
              "110  <deepchem.feat.mol_graphs.ConvMol object at 0x...  ...                 c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43\n",
              "111  <deepchem.feat.mol_graphs.ConvMol object at 0x...  ...                             Cc1occc1C(=O)Nc2ccccc2\n",
              "112  <deepchem.feat.mol_graphs.ConvMol object at 0x...  ...  OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...\n",
              "\n",
              "[113 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "123IMrMb53O9"
      },
      "source": [
        "# Creating Datasets\n",
        "\n",
        "Now let's talk about how you can create your own datasets.  Creating a `NumpyDataset` is very simple: just pass the arrays containing the data to the constructor.  Let's create some random arrays, then wrap them in a NumpyDataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkRdOyGA53O9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6233c291-3957-47c8-a644-099785c96458"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.random.random((10, 5))\n",
        "y = np.random.random((10, 2))\n",
        "dataset = dc.data.NumpyDataset(X=X, y=y)\n",
        "print(dataset)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<NumpyDataset X.shape: (10, 5), y.shape: (10, 2), w.shape: (10, 1), ids: [0 1 2 3 4 5 6 7 8 9], task_names: [0 1]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzn_J8vmgLsl",
        "outputId": "46b8184b-d0f8-4b44-8730-3a79b4ac11b6"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NumpyDataset X.shape: (10, 5), y.shape: (10, 2), w.shape: (10, 1), ids: [0 1 2 3 4 5 6 7 8 9], task_names: [0 1]>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHQrAgib53O9"
      },
      "source": [
        "Notice that we did not specify weights or IDs.  These are optional, as is `y` for that matter.  Only `X` is required.  Since we left them out, it automatically built `w` and `ids` arrays for us, setting all weights to 1 and setting the IDs to integer indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFcWu-4J53O-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "49a70fa6-3f24-49a9-e925-1d189186447b"
      },
      "source": [
        "dataset.to_dataframe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "      <th>w</th>\n",
              "      <th>ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.807527</td>\n",
              "      <td>0.016863</td>\n",
              "      <td>0.541549</td>\n",
              "      <td>0.675612</td>\n",
              "      <td>0.246332</td>\n",
              "      <td>0.593415</td>\n",
              "      <td>0.105518</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.420006</td>\n",
              "      <td>0.452954</td>\n",
              "      <td>0.865750</td>\n",
              "      <td>0.241010</td>\n",
              "      <td>0.515808</td>\n",
              "      <td>0.263764</td>\n",
              "      <td>0.436931</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.415410</td>\n",
              "      <td>0.885730</td>\n",
              "      <td>0.387790</td>\n",
              "      <td>0.955610</td>\n",
              "      <td>0.055231</td>\n",
              "      <td>0.812400</td>\n",
              "      <td>0.288368</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.167741</td>\n",
              "      <td>0.120210</td>\n",
              "      <td>0.041519</td>\n",
              "      <td>0.284706</td>\n",
              "      <td>0.962192</td>\n",
              "      <td>0.081480</td>\n",
              "      <td>0.295286</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.602042</td>\n",
              "      <td>0.385652</td>\n",
              "      <td>0.503271</td>\n",
              "      <td>0.013634</td>\n",
              "      <td>0.470310</td>\n",
              "      <td>0.324513</td>\n",
              "      <td>0.502949</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.902019</td>\n",
              "      <td>0.342711</td>\n",
              "      <td>0.461573</td>\n",
              "      <td>0.955236</td>\n",
              "      <td>0.458136</td>\n",
              "      <td>0.768045</td>\n",
              "      <td>0.919536</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.049351</td>\n",
              "      <td>0.073925</td>\n",
              "      <td>0.924660</td>\n",
              "      <td>0.757646</td>\n",
              "      <td>0.421659</td>\n",
              "      <td>0.514853</td>\n",
              "      <td>0.252070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.417806</td>\n",
              "      <td>0.916411</td>\n",
              "      <td>0.875386</td>\n",
              "      <td>0.190135</td>\n",
              "      <td>0.170035</td>\n",
              "      <td>0.543366</td>\n",
              "      <td>0.545429</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.128200</td>\n",
              "      <td>0.068048</td>\n",
              "      <td>0.464277</td>\n",
              "      <td>0.721848</td>\n",
              "      <td>0.861078</td>\n",
              "      <td>0.294488</td>\n",
              "      <td>0.774635</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.602816</td>\n",
              "      <td>0.750494</td>\n",
              "      <td>0.996557</td>\n",
              "      <td>0.524671</td>\n",
              "      <td>0.474758</td>\n",
              "      <td>0.210928</td>\n",
              "      <td>0.193611</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         X1        X2        X3        X4  ...        y1        y2    w  ids\n",
              "0  0.807527  0.016863  0.541549  0.675612  ...  0.593415  0.105518  1.0    0\n",
              "1  0.420006  0.452954  0.865750  0.241010  ...  0.263764  0.436931  1.0    1\n",
              "2  0.415410  0.885730  0.387790  0.955610  ...  0.812400  0.288368  1.0    2\n",
              "3  0.167741  0.120210  0.041519  0.284706  ...  0.081480  0.295286  1.0    3\n",
              "4  0.602042  0.385652  0.503271  0.013634  ...  0.324513  0.502949  1.0    4\n",
              "5  0.902019  0.342711  0.461573  0.955236  ...  0.768045  0.919536  1.0    5\n",
              "6  0.049351  0.073925  0.924660  0.757646  ...  0.514853  0.252070  1.0    6\n",
              "7  0.417806  0.916411  0.875386  0.190135  ...  0.543366  0.545429  1.0    7\n",
              "8  0.128200  0.068048  0.464277  0.721848  ...  0.294488  0.774635  1.0    8\n",
              "9  0.602816  0.750494  0.996557  0.524671  ...  0.210928  0.193611  1.0    9\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYWWQafw53O-"
      },
      "source": [
        "What about creating a DiskDataset?  If you have the data in NumPy arrays, you can call `DiskDataset.from_numpy()` to save it to disk.  Since this is just a tutorial, we will save it to a temporary directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAsgP2Vt53O-"
      },
      "source": [
        "import tempfile\n",
        "\n",
        "with tempfile.TemporaryDirectory() as data_dir:\n",
        "    disk_dataset = dc.data.DiskDataset.from_numpy(X=X, y=y, data_dir=data_dir)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46hCeuGYgw18"
      },
      "source": [
        " disk_dataset = dc.data.DiskDataset.from_numpy(X=X, y=y, data_dir=data_dir)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEt_MPPNhAWq",
        "outputId": "f1918cf7-63fd-4ff9-f283-1856eef34bcb"
      },
      "source": [
        "disk_dataset"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DiskDataset X.shape: (10, 5), y.shape: (10, 2), w.shape: (10, 1), ids: [0 1 2 3 4 5 6 7 8 9], task_names: [0 1]>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGsiQjzr53O-"
      },
      "source": [
        "What about larger datasets that can't fit in memory?  What if you have some huge files on disk containing data on hundreds of millions of molecules?  The process for creating a DiskDataset from them is slightly more involved.  Fortunately, DeepChem's `DataLoader` framework can automate most of the work for you.  That is a larger subject, so we will return to it in a later tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0cZcB_YQFHU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDrI47hgQF2I"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgoX6fB1QJ0e"
      },
      "source": [
        "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')\n",
        "train_dataset, valid_dataset, test_dataset = datasets"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpoWGxcehSw4",
        "outputId": "d511f896-676f-4079-fda6-7139d9e4c013"
      },
      "source": [
        "valid_dataset"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DiskDataset X.shape: (113,), y.shape: (113, 1), w.shape: (113, 1), ids: ['Nc1ncnc2nc[nH]c12 ' 'Nc1nc(O)nc2nc[nH]c12 '\n",
              " 'Fc1cccc(F)c1C(=O)NC(=O)Nc2cc(Cl)c(F)c(Cl)c2F ' ...\n",
              " 'OC(Cn1cncn1)(Cn2cncn2)c3ccc(F)cc3F '\n",
              " 'FC(F)(F)c1cccc(c1)N2CC(CCl)C(Cl)C2=O' 'CC1(C)CON(Cc2ccccc2Cl)C1=O'], task_names: ['measured log solubility in mols per litre']>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UN0lwh7QMve"
      },
      "source": [
        "model = dc.models.GraphConvModel(n_tasks=1, mode='regression', dropout=0.2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHIpxCYBQOcc",
        "outputId": "4f569444-695c-468f-ae5d-ee91d6fda8e9"
      },
      "source": [
        "model.fit(train_dataset, nb_epoch=50)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(330,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(330, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(1084,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(1084, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(852,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(852, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(116,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(116, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(330,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(330, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(1084,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(1084, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(852,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(852, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(116,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(116, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(330,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(330, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(1084,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(1084, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(852,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(852, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(116,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(116, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(371,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(371, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(1066,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(1066, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(993,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(993, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(136, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(371,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(371, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(1066,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(1066, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(993,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(993, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(136, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(371,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(371, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(1066,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(1066, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(993,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(993, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(136, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16760950088500975"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dbjJt3qQQJB",
        "outputId": "27f13aa2-7350-49ba-d6d2-af6702fefca8"
      },
      "source": [
        "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
        "print(\"Training set score:\", model.evaluate(train_dataset, [metric], transformers))\n",
        "print(\"Test set score:\", model.evaluate(test_dataset, [metric], transformers))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set score: {'pearson_r2_score': 0.8654287834745752}\n",
            "Test set score: {'pearson_r2_score': 0.6136101898455377}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VwqrRQaQgI5",
        "outputId": "5cd2200f-b64e-40d5-a2cb-244adeae5eed"
      },
      "source": [
        "solubilities = model.predict_on_batch(test_dataset.X[:10])\n",
        "for molecule, solubility, test_solubility in zip(test_dataset.ids, solubilities, test_dataset.y):\n",
        "    print(solubility, test_solubility, molecule)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.0156411] [-1.60114461] c1cc2ccc3cccc4ccc(c1)c2c34\n",
            "[1.352353] [0.20848251] Cc1cc(=O)[nH]c(=S)[nH]1\n",
            "[-0.3577692] [-0.01602738] Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 \n",
            "[-1.3251768] [-2.82191713] c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45\n",
            "[-0.6120652] [-0.52891635] C1=Cc2cccc3cccc1c23\n",
            "[1.3723112] [1.10168349] CC1CO1\n",
            "[-0.12451547] [-0.88987406] CCN2c1ccccc1N(C)C(=S)c3cccnc23 \n",
            "[-0.9751379] [-0.52649706] CC12CCC3C(CCc4cc(O)ccc34)C2CCC1=O\n",
            "[-1.271826] [-0.76358725] Cn2cc(c1ccccc1)c(=O)c(c2)c3cccc(c3)C(F)(F)F\n",
            "[-0.33278984] [-0.64020358] ClC(Cl)(Cl)C(NC=O)N1C=CN(C=C1)C(NC=O)C(Cl)(Cl)Cl \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq1CNCFwQmm6",
        "outputId": "0abc6b3a-e164-4fd4-eccd-c1b409ccfd83"
      },
      "source": [
        "solubilities"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.0156411 ],\n",
              "       [ 1.352353  ],\n",
              "       [-0.3577692 ],\n",
              "       [-1.3251768 ],\n",
              "       [-0.6120652 ],\n",
              "       [ 1.3723112 ],\n",
              "       [-0.12451547],\n",
              "       [-0.9751379 ],\n",
              "       [-1.271826  ],\n",
              "       [-0.33278984]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBEzlG3ZRA3x"
      },
      "source": [
        "# Advanced model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WaM2EICRaoz"
      },
      "source": [
        "### Hyperparameter Optimization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8sFw1cJSVf-"
      },
      "source": [
        "Let's start by loading the HIV dataset. It classifies over 40,000 molecules based on whether they inhibit HIV replication.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFpcKd1lRC0S"
      },
      "source": [
        "\n",
        "tasks, datasets, transformers = dc.molnet.load_hiv(featurizer='ECFP', splitter='scaffold')\n",
        "train_dataset, valid_dataset, test_dataset = datasets"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRtplnPil0JO",
        "outputId": "1276775a-f767-4ddd-d2aa-677c79f739d5"
      },
      "source": [
        "train_dataset.y[:10]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV5wpwS4Sc_r"
      },
      "source": [
        "Now let's train a model on it. We will use a MultitaskClassifier, which is just a stack of dense layers. But that still leaves a lot of options. How many layers should there be, and how wide should each one be? What dropout rate should we use? What learning rate?\n",
        "\n",
        "These are called hyperparameters. The standard way to select them is to try lots of values, train each model on the training set, and evaluate it on the validation set. This lets us see which ones work best.\n",
        "\n",
        "You could do that by hand, but usually it's easier to let the computer do it for you. DeepChem provides a selection of hyperparameter optimization algorithms, which are found in the dc.hyper package. For this example we'll use GridHyperparamOpt, which is the most basic method. We just give it a list of options for each hyperparameter and it exhaustively tries all combinations of them.\n",
        "\n",
        "The lists of options are defined by a dict that we provide. For each of the model's arguments, we provide a list of values to try. In this example we consider three possible sets of hidden layers: a single layer of width 500, a single layer of width 1000, or two layers each of width 1000. We also consider two dropout rates (20% and 50%) and two learning rates (0.001 and 0.0001)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O8UEcvjRDJb"
      },
      "source": [
        "params_dict = {\n",
        "    'n_tasks': [len(tasks)],\n",
        "    'n_features': [1024],\n",
        "    'layer_sizes': [[500], [1000], [1000, 1000]],\n",
        "    'dropouts': [0.2, 0.5],\n",
        "    'learning_rate': [0.001, 0.0001]\n",
        "}\n",
        "optimizer = dc.hyper.GridHyperparamOpt(dc.models.MultitaskClassifier)\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
        "best_model, best_hyperparams, all_results = optimizer.hyperparam_search(\n",
        "        params_dict, train_dataset, valid_dataset, metric, transformers)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keSk3TAeSp69"
      },
      "source": [
        "hyperparam_search() returns three arguments: the best model it found, the hyperparameters for that model, and a full listing of the validation score for every model. Let's take a look at the last one.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIR-vHZMo4yN",
        "outputId": "2bdc0719-f76b-4c85-df65-a61154cc8261"
      },
      "source": [
        "best_hyperparams"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dropouts': 0.5,\n",
              " 'layer_sizes': [1000],\n",
              " 'learning_rate': 0.001,\n",
              " 'n_features': 1024,\n",
              " 'n_tasks': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1m35ielS31f",
        "outputId": "070e79e6-e773-46ac-8c3e-13534271473b"
      },
      "source": [
        "all_results\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_dropouts_0.200000_layer_sizes[1000, 1000]_learning_rate_0.000100_n_features_1024_n_tasks_1': 0.772286216441309,\n",
              " '_dropouts_0.200000_layer_sizes[1000, 1000]_learning_rate_0.001000_n_features_1024_n_tasks_1': 0.7313130756417794,\n",
              " '_dropouts_0.200000_layer_sizes[1000]_learning_rate_0.000100_n_features_1024_n_tasks_1': 0.7672707843425435,\n",
              " '_dropouts_0.200000_layer_sizes[1000]_learning_rate_0.001000_n_features_1024_n_tasks_1': 0.7668819199490495,\n",
              " '_dropouts_0.200000_layer_sizes[500]_learning_rate_0.000100_n_features_1024_n_tasks_1': 0.7746040931804821,\n",
              " '_dropouts_0.200000_layer_sizes[500]_learning_rate_0.001000_n_features_1024_n_tasks_1': 0.7725372942386832,\n",
              " '_dropouts_0.500000_layer_sizes[1000, 1000]_learning_rate_0.000100_n_features_1024_n_tasks_1': 0.7609050436018028,\n",
              " '_dropouts_0.500000_layer_sizes[1000, 1000]_learning_rate_0.001000_n_features_1024_n_tasks_1': 0.7583705357142858,\n",
              " '_dropouts_0.500000_layer_sizes[1000]_learning_rate_0.000100_n_features_1024_n_tasks_1': 0.7517407039976485,\n",
              " '_dropouts_0.500000_layer_sizes[1000]_learning_rate_0.001000_n_features_1024_n_tasks_1': 0.7755257324123066,\n",
              " '_dropouts_0.500000_layer_sizes[500]_learning_rate_0.000100_n_features_1024_n_tasks_1': 0.7583452748383304,\n",
              " '_dropouts_0.500000_layer_sizes[500]_learning_rate_0.001000_n_features_1024_n_tasks_1': 0.7662603493043308}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oQOr_S8Wuzq"
      },
      "source": [
        "We can see a few general patterns. Using two layers with the larger learning rate doesn't work very well. It seems the deeper model requires a smaller learning rate. We also see that 20% dropout usually works better than 50%. Once we narrow down the list of models based on these observations, all the validation scores are very close to each other, probably close enough that the remaining variation is mainly noise. It doesn't seem to make much difference which of the remaining hyperparameter sets we use, so let's arbitrarily pick a single layer of width 1000 and learning rate of 0.0001.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd-GGBvGSuuz",
        "outputId": "cdee8f00-b9a8-4258-b0b5-aa8ea5c59a90"
      },
      "source": [
        "best_model"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultitaskClassifier(activation_fns=None, bias_init_consts=None, dropouts=None,\n",
              "                    layer_sizes=None, n_classes=2, n_features=1024, n_tasks=1,\n",
              "                    residual=None, weight_decay_penalty=None,\n",
              "                    weight_decay_penalty_type=None, weight_init_stddevs=None)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvQ7XL93W8f7"
      },
      "source": [
        "## Early Stopping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcKKk_Z8XBYC"
      },
      "source": [
        "There is one other important hyperparameter we haven't considered yet: how long we train the model for. GridHyperparamOpt trains each for a fixed, fairly small number of epochs. That isn't necessarily the best number.\n",
        "\n",
        "You might expect that the longer you train, the better your model will get, but that isn't usually true. If you train too long, the model will usually start overfitting to irrelevant details of the training set. You can tell when this happens because the validation set score stops increasing and may even decrease, while the score on the training set continues to improve.\n",
        "\n",
        "Fortunately, we don't need to train lots of different models for different numbers of steps to identify the optimal number. We just train it once, monitor the validation score, and keep whichever parameters maximize it. This is called \"early stopping\". DeepChem's ValidationCallback class can do this for us automatically. In the example below, we have it compute the validation set's ROC AUC every 1000 training steps. If you add the save_dir argument, it will also save a copy of the best model parameters to disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L3fXI_3Szjb",
        "outputId": "69b0bc7c-8c5b-4934-b051-62d17ac86cbb"
      },
      "source": [
        "model = dc.models.MultitaskClassifier(n_tasks=len(tasks),\n",
        "                                      n_features=1024,\n",
        "                                      layer_sizes=[1000],\n",
        "                                      dropouts=0.2,\n",
        "                                      learning_rate=0.0001)\n",
        "callback = dc.models.ValidationCallback(valid_dataset, 1000, metric)\n",
        "model.fit(train_dataset, nb_epoch=50, callbacks=callback)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1000 validation: roc_auc_score=0.741894\n",
            "Step 2000 validation: roc_auc_score=0.773571\n",
            "Step 3000 validation: roc_auc_score=0.77484\n",
            "Step 4000 validation: roc_auc_score=0.777733\n",
            "Step 5000 validation: roc_auc_score=0.761533\n",
            "Step 6000 validation: roc_auc_score=0.769077\n",
            "Step 7000 validation: roc_auc_score=0.776145\n",
            "Step 8000 validation: roc_auc_score=0.758731\n",
            "Step 9000 validation: roc_auc_score=0.760951\n",
            "Step 10000 validation: roc_auc_score=0.762702\n",
            "Step 11000 validation: roc_auc_score=0.767951\n",
            "Step 12000 validation: roc_auc_score=0.760645\n",
            "Step 13000 validation: roc_auc_score=0.773707\n",
            "Step 14000 validation: roc_auc_score=0.760608\n",
            "Step 15000 validation: roc_auc_score=0.761227\n",
            "Step 16000 validation: roc_auc_score=0.765002\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6852291107177735"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4H09316pXes"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}